{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b2d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchaudio in /Users/emily/.local/lib/python3.9/site-packages (2.7.0)\n",
      "Requirement already satisfied: torch in /Users/emily/.local/lib/python3.9/site-packages (2.7.0)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[K     |████████████████████████████████| 260 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/emily/.local/lib/python3.9/site-packages (3.9.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp39-cp39-macosx_12_0_arm64.whl (11.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /Users/emily/.local/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/emily/.local/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /Users/emily/.local/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/emily/.local/lib/python3.9/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/emily/.local/lib/python3.9/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: fsspec in /Users/emily/.local/lib/python3.9/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/emily/.local/lib/python3.9/site-packages (from librosa) (5.2.1)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.3 in /Users/emily/.local/lib/python3.9/site-packages (from librosa) (2.0.2)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.60.0-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.7 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soxr>=0.3.2\n",
      "  Downloading soxr-0.5.0.post1-cp39-cp39-macosx_11_0_arm64.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting msgpack>=1.0\n",
      "  Downloading msgpack-1.1.1-cp39-cp39-macosx_11_0_arm64.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting pooch>=1.1\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 8.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Collecting joblib>=1.0\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 19.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/emily/.local/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/emily/.local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0\n",
      "  Downloading llvmlite-0.43.0-cp39-cp39-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8 MB 38.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Users/emily/.local/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.32.4)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/emily/.local/lib/python3.9/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: six>=1.5 in /Users/emily/.local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Collecting cffi>=1.0\n",
      "  Using cached cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl (178 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/emily/.local/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/emily/.local/lib/python3.9/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: pycparser, threadpoolctl, scipy, llvmlite, joblib, cffi, soxr, soundfile, scikit-learn, pooch, numba, msgpack, lazy-loader, audioread, librosa\n",
      "Successfully installed audioread-3.0.1 cffi-1.17.1 joblib-1.5.2 lazy-loader-0.4 librosa-0.11.0 llvmlite-0.43.0 msgpack-1.1.1 numba-0.60.0 pooch-1.8.2 pycparser-2.22 scikit-learn-1.6.1 scipy-1.13.1 soundfile-0.13.1 soxr-0.5.0.post1 threadpoolctl-3.6.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchaudio torch librosa matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f86142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb27123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[K     |████████████████████████████████| 494 kB 598 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchaudio in /Users/emily/.local/lib/python3.9/site-packages (2.7.0)\n",
      "Collecting fsspec[http]<=2025.3.0,>=2023.1.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[K     |████████████████████████████████| 193 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/emily/.local/lib/python3.9/site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 257 kB/s eta 0:00:01    |███▍                            | 3.3 MB 70 kB/s eta 0:06:38     |█████████████████████████▌      | 24.9 MB 73 kB/s eta 0:01:27     |████████████████████████████▉   | 28.2 MB 73 kB/s eta 0:00:42\n",
      "\u001b[?25hCollecting tqdm>=4.66.3\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: pandas in /Users/emily/.local/lib/python3.9/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/emily/.local/lib/python3.9/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/emily/.local/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: filelock in /Users/emily/.local/lib/python3.9/site-packages (from datasets) (3.18.0)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[K     |████████████████████████████████| 561 kB 235 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==2.7.0 in /Users/emily/.local/lib/python3.9/site-packages (from torchaudio) (2.7.0)\n",
      "Requirement already satisfied: fsspec in /Users/emily/.local/lib/python3.9/site-packages (from torch==2.7.0->torchaudio) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/emily/.local/lib/python3.9/site-packages (from torch==2.7.0->torchaudio) (4.13.2)\n",
      "Requirement already satisfied: jinja2 in /Users/emily/.local/lib/python3.9/site-packages (from torch==2.7.0->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: networkx in /Users/emily/.local/lib/python3.9/site-packages (from torch==2.7.0->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/emily/.local/lib/python3.9/site-packages (from torch==2.7.0->torchaudio) (1.14.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.12.15-cp39-cp39-macosx_11_0_arm64.whl (469 kB)\n",
      "\u001b[K     |████████████████████████████████| 469 kB 154 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.1-cp39-cp39-macosx_11_0_arm64.whl (89 kB)\n",
      "\u001b[K     |████████████████████████████████| 89 kB 61 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.7.0-cp39-cp39-macosx_11_0_arm64.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 70 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.5.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.6.4-cp39-cp39-macosx_11_0_arm64.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 66 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting aiosignal>=1.4.0\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.2-cp39-cp39-macosx_11_0_arm64.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 90 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting hf-xet<2.0.0,>=1.1.3\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 179 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/emily/.local/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/emily/.local/lib/python3.9/site-packages (from sympy>=1.13.3->torch==2.7.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/emily/.local/lib/python3.9/site-packages (from jinja2->torch==2.7.0->torchaudio) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/emily/.local/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/emily/.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/emily/.local/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/emily/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Installing collected packages: propcache, multidict, frozenlist, yarl, attrs, async-timeout, aiosignal, aiohappyeyeballs, tqdm, pyyaml, hf-xet, fsspec, dill, aiohttp, xxhash, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.9 huggingface-hub-0.34.4 multidict-6.6.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-21.0.0 pyyaml-6.0.2 tqdm-4.67.1 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348d8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emily/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_lzma'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Speech Commands, an audio dataset of spoken words designed to help train and evaluate keyword spotting systems. \"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m     24\u001b[0m _CITATION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124m@article\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mspeechcommandsv2,\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124m   author = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{Warden}\u001b[39;00m\u001b[38;5;124m, P.},\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     39\u001b[0m _DESCRIPTION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124mThis is a set of one-second .wav audio files, each containing a single spoken\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124mEnglish word or background noise. These words are from a small set of commands, and are spoken by a\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Column, Dataset\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/arrow_dataset.py:75\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/arrow_reader.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _split_re, filenames_for_dataset_split\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryTable, MemoryMappedTable, Table, concat_tables\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/download/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamingDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadManager, DownloadMode\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/download/download_manager.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     ArchiveIterable,\n\u001b[1;32m     34\u001b[0m     FilesIterable,\n\u001b[1;32m     35\u001b[0m     cached_path,\n\u001b[1;32m     36\u001b[0m     is_relative_path,\n\u001b[1;32m     37\u001b[0m     stack_multiprocessing_download_progress_bars,\n\u001b[1;32m     38\u001b[0m     url_or_path_join,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_size_checksum_dict\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger, tqdm\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/utils/file_utils.py:43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tqdm, logging\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtractManager\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrackedIterableFromGenerator\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/utils/extract.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/lzma.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_compression\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2021 The HuggingFace Datasets Authors and the current dataset script contributor.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Speech Commands, an audio dataset of spoken words designed to help train and evaluate keyword spotting systems. \"\"\"\n",
    "\n",
    "\n",
    "import textwrap\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "_CITATION = \"\"\"\n",
    "@article{speechcommandsv2,\n",
    "   author = { {Warden}, P.},\n",
    "    title = \"{Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition}\",\n",
    "  journal = {ArXiv e-prints},\n",
    "  archivePrefix = \"arXiv\",\n",
    "  eprint = {1804.03209},\n",
    "  primaryClass = \"cs.CL\",\n",
    "  keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},\n",
    "    year = 2018,\n",
    "    month = apr,\n",
    "    url = {https://arxiv.org/abs/1804.03209},\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\n",
    "This is a set of one-second .wav audio files, each containing a single spoken\n",
    "English word or background noise. These words are from a small set of commands, and are spoken by a\n",
    "variety of different speakers. This data set is designed to help train simple\n",
    "machine learning models. This dataset is covered in more detail at\n",
    "[https://arxiv.org/abs/1804.03209](https://arxiv.org/abs/1804.03209).\n",
    "\n",
    "Version 0.01 of the data set (configuration `\"v0.01\"`) was released on August 3rd 2017 and contains\n",
    "64,727 audio files.\n",
    "\n",
    "In version 0.01 thirty different words were recoded: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
    "\"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\",\n",
    "\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", \"Wow\".\n",
    "\n",
    "\n",
    "In version 0.02 more words were added: \"Backward\", \"Forward\", \"Follow\", \"Learn\", \"Visual\".\n",
    "\n",
    "In both versions, ten of them are used as commands by convention: \"Yes\", \"No\", \"Up\", \"Down\", \"Left\",\n",
    "\"Right\", \"On\", \"Off\", \"Stop\", \"Go\". Other words are considered to be auxiliary (in current implementation\n",
    "it is marked by `True` value of `\"is_unknown\"` feature). Their function is to teach a model to distinguish core words\n",
    "from unrecognized ones.\n",
    "\n",
    "The `_silence_` class contains a set of longer audio clips that are either recordings or\n",
    "a mathematical simulation of noise.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_LICENSE = \"Creative Commons BY 4.0 License\"\n",
    "\n",
    "_URL = \"https://www.tensorflow.org/datasets/catalog/speech_commands\"\n",
    "\n",
    "_DL_URL = \"https://s3.amazonaws.com/datasets.huggingface.co/SpeechCommands/{name}/{name}_{split}.tar.gz\"\n",
    "\n",
    "WORDS = [\n",
    "    \"yes\",\n",
    "    \"no\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"stop\",\n",
    "    \"go\",\n",
    "]\n",
    "\n",
    "UNKNOWN_WORDS_V1 = [\n",
    "    \"zero\",\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"four\",\n",
    "    \"five\",\n",
    "    \"six\",\n",
    "    \"seven\",\n",
    "    \"eight\",\n",
    "    \"nine\",\n",
    "    \"bed\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"happy\",\n",
    "    \"house\",\n",
    "    \"marvin\",\n",
    "    \"sheila\",\n",
    "    \"tree\",\n",
    "    \"wow\",\n",
    "]\n",
    "\n",
    "UNKNOWN_WORDS_V2 = UNKNOWN_WORDS_V1 + [\n",
    "    \"backward\",\n",
    "    \"forward\",\n",
    "    \"follow\",\n",
    "    \"learn\",\n",
    "    \"visual\",\n",
    "]\n",
    "\n",
    "SILENCE = \"_silence_\"  # background noise\n",
    "LABELS_V1 = WORDS + UNKNOWN_WORDS_V1 + [SILENCE]\n",
    "LABELS_V2 = WORDS + UNKNOWN_WORDS_V2 + [SILENCE]\n",
    "\n",
    "\n",
    "class SpeechCommandsConfig(datasets.BuilderConfig):\n",
    "    \"\"\"BuilderConfig for SpeechCommands.\"\"\"\n",
    "\n",
    "    def __init__(self, labels, **kwargs):\n",
    "        super(SpeechCommandsConfig, self).__init__(**kwargs)\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class SpeechCommands(datasets.GeneratorBasedBuilder):\n",
    "    BUILDER_CONFIGS = [\n",
    "        SpeechCommandsConfig(\n",
    "            name=\"v0.01\",\n",
    "            description=textwrap.dedent(\n",
    "                \"\"\"\\\n",
    "                Version 0.01 of the SpeechCommands dataset. Contains 30 words\n",
    "                (20 of them are auxiliary) and background noise.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            labels=LABELS_V1,\n",
    "            version=datasets.Version(\"0.1.0\"),\n",
    "        ),\n",
    "        SpeechCommandsConfig(\n",
    "            name=\"v0.02\",\n",
    "            description=textwrap.dedent(\n",
    "                \"\"\"\\\n",
    "                Version 0.02 of the SpeechCommands dataset.\n",
    "                Contains 35 words (25 of them are auxiliary) and background noise.\n",
    "                \"\"\"\n",
    "            ),\n",
    "            labels=LABELS_V2,\n",
    "            version=datasets.Version(\"0.2.0\"),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    def _info(self):\n",
    "        return datasets.DatasetInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"file\": datasets.Value(\"string\"),\n",
    "                    \"audio\": datasets.features.Audio(sampling_rate=16_000),\n",
    "                    \"label\": datasets.ClassLabel(names=self.config.labels),\n",
    "                    \"is_unknown\": datasets.Value(\"bool\"),\n",
    "                    \"speaker_id\": datasets.Value(\"string\"),\n",
    "                    \"utterance_id\": datasets.Value(\"int8\"),\n",
    "                }\n",
    "            ),\n",
    "            homepage=_URL,\n",
    "            citation=_CITATION,\n",
    "            license=_LICENSE,\n",
    "            version=self.config.version,\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "\n",
    "        archive_paths = dl_manager.download(\n",
    "            {\n",
    "                \"train\": _DL_URL.format(name=self.config.name, split=\"train\"),\n",
    "                \"validation\": _DL_URL.format(name=self.config.name, split=\"validation\"),\n",
    "                \"test\": _DL_URL.format(name=self.config.name, split=\"test\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return [\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.TRAIN,\n",
    "                gen_kwargs={\n",
    "                    \"archive\": dl_manager.iter_archive(archive_paths[\"train\"]),\n",
    "                },\n",
    "            ),\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.VALIDATION,\n",
    "                gen_kwargs={\n",
    "                    \"archive\": dl_manager.iter_archive(archive_paths[\"validation\"]),\n",
    "                },\n",
    "            ),\n",
    "            datasets.SplitGenerator(\n",
    "                name=datasets.Split.TEST,\n",
    "                gen_kwargs={\n",
    "                    \"archive\": dl_manager.iter_archive(archive_paths[\"test\"]),\n",
    "                },\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def _generate_examples(self, archive):\n",
    "        for path, file in archive:\n",
    "            if not path.endswith(\".wav\"):\n",
    "                continue\n",
    "\n",
    "            word, audio_filename = path.split(\"/\")\n",
    "            is_unknown = False\n",
    "\n",
    "            if word == SILENCE:\n",
    "                speaker_id, utterance_id = None, 0\n",
    "\n",
    "            else:  # word is either in WORDS or unknown\n",
    "                if word not in WORDS:\n",
    "                    is_unknown = True\n",
    "                # an audio filename looks like `0bac8a71_nohash_0.wav`\n",
    "                speaker_id, _, utterance_id = audio_filename.split(\".wav\")[0].split(\"_\")\n",
    "\n",
    "            yield path, {\n",
    "                \"file\": path,\n",
    "                \"audio\": {\"path\": path, \"bytes\": file.read()},\n",
    "                \"label\": word,\n",
    "                \"is_unknown\": is_unknown,\n",
    "                \"speaker_id\": speaker_id,\n",
    "                \"utterance_id\": utterance_id,\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496910b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 將部分資料儲存為 .wav 檔案\n",
    "dataset = load_dataset(\"speech_commands\", \"v0.02\", split=\"train[:1%]\")\n",
    "\n",
    "os.makedirs(\"samples\", exist_ok=True)\n",
    "\n",
    "for i, sample in enumerate(dataset):\n",
    "    audio = sample[\"audio\"]\n",
    "    path = f\"samples/{i}_{sample['label']}.wav\"\n",
    "    audio[\"array\"].tofile(path)\n",
    "    if i >= 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
